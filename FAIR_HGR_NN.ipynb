{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fairml-research/HGR_NN/blob/main/FAIR_HGR_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e1e4f7dc",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T18:03:41.438445Z",
          "start_time": "2024-01-04T18:03:41.427507Z"
        },
        "id": "e1e4f7dc"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone \"https://github.com/fairml-research/HGR_NN.git\"\n",
        "import sys, os\n",
        "os.chdir('HGR_NN')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELjNoqXTLiSz",
        "outputId": "df7dc61a-9574-4349-8be1-2941b566e8c2"
      },
      "id": "ELjNoqXTLiSz",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'HGR_NN'...\n",
            "remote: Enumerating objects: 22, done.\u001b[K\n",
            "remote: Counting objects: 100% (22/22), done.\u001b[K\n",
            "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
            "remote: Total 22 (delta 9), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (22/22), 79.66 KiB | 2.84 MiB/s, done.\n",
            "Resolving deltas: 100% (9/9), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "fb4327ef",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T18:12:41.488170Z",
          "start_time": "2024-01-04T18:12:39.909400Z"
        },
        "scrolled": true,
        "id": "fb4327ef"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import sklearn as sk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a61fb6c0",
      "metadata": {
        "id": "a61fb6c0"
      },
      "source": [
        "### 1) **IMPORT THE DATA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d8554ae5",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T18:08:49.527928Z",
          "start_time": "2024-01-04T18:08:47.033627Z"
        },
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8554ae5",
        "outputId": "a5151a95-935f-47d3-f33f-e1230af97a04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-01-04 21:28:30--  https://raw.githubusercontent.com/SoftStackFactory/data-science-fall2019/master/data/census_2015/acs2015_census_tract_data.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14448669 (14M) [text/plain]\n",
            "Saving to: ‘acs2015_census_tract_data.csv’\n",
            "\n",
            "acs2015_census_trac 100%[===================>]  13.78M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-01-04 21:28:31 (130 MB/s) - ‘acs2015_census_tract_data.csv’ saved [14448669/14448669]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget \"https://raw.githubusercontent.com/SoftStackFactory/data-science-fall2019/master/data/census_2015/acs2015_census_tract_data.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "eebbdd12",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T18:16:12.667798Z",
          "start_time": "2024-01-04T18:16:12.409052Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eebbdd12",
        "outputId": "15bade8f-eada-4b49-f23a-9f6d9b0eb060"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features X: 72727 samples, 82 attributes\n",
            "targets y: 72727 samples\n",
            "sensitives Z: 72727 samples, 1 attributes\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import sys, os\n",
        "sys.path.append(os.path.abspath(os.path.join('../..')))\n",
        "\n",
        "def load_USCENSUS_data(path):\n",
        "#    column_names = [\"age\",\"sex\",\"bmi\",\"children\",\"smoker\",\"region\",\"charges\"]\n",
        "    input_data = pd.read_csv(path, sep=',')\n",
        "    input_data=input_data.drop(columns=['CensusTract','County'])\n",
        "    input_data=input_data.dropna()\n",
        "    input_data['Women']=input_data['Women']/input_data['TotalPop']\n",
        "    input_data.dtypes\n",
        "    sensitive_attribs = ['Women']\n",
        "    Z = (input_data.loc[:, sensitive_attribs])\n",
        "\n",
        "    y = input_data['ChildPoverty']\n",
        "\n",
        "    # features; note that the 'target' and sentive attribute columns are dropped\n",
        "    X = (input_data\n",
        "         .drop(columns=['Poverty', 'ChildPoverty','Women','Men'])\n",
        "         .pipe(pd.get_dummies))\n",
        "\n",
        "    print(f\"features X: {X.shape[0]} samples, {X.shape[1]} attributes\")\n",
        "    print(f\"targets y: {y.shape[0]} samples\")\n",
        "    print(f\"sensitives Z: {Z.shape[0]} samples, {Z.shape[1]} attributes\")\n",
        "    return X, y, Z\n",
        "\n",
        "\n",
        "# load ICU data set\n",
        "X, y, Z = load_USCENSUS_data('acs2015_census_tract_data.csv')\n",
        "\n",
        "# split into train/test set\n",
        "X_train, X_test, y_train, y_test, s_train, s_test = train_test_split(X, y, Z, test_size=0.2, random_state=7)\n",
        "\n",
        "# standardize the data\n",
        "scaler = StandardScaler().fit(X_train)\n",
        "scale_df = lambda df, scaler: pd.DataFrame(scaler.transform(df), columns=df.columns, index=df.index)\n",
        "X_train = X_train.pipe(scale_df, scaler)\n",
        "X_test = X_test.pipe(scale_df, scaler)\n",
        "\n",
        "meanYtrain=np.mean(y_train)\n",
        "stdYtrain=np.std(y_train)\n",
        "y_train=(y_train-meanYtrain)/stdYtrain\n",
        "y_test =(y_test-meanYtrain)/stdYtrain\n",
        "s_train=s_train.values.squeeze(1)\n",
        "s_test=s_test.values.squeeze(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1be4189f",
      "metadata": {
        "id": "1be4189f"
      },
      "source": [
        "###2) UNFAIR PREDICTOR MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "ae11700c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T18:20:11.138896Z",
          "start_time": "2024-01-04T18:19:53.441835Z"
        },
        "code_folding": [
          33,
          50
        ],
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae11700c",
        "outputId": "64a1a075-f78e-4f7c-9d5d-e8b29dcb4cef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Bar desc (file 1000): 100%|██████████| 1001/1001 [00:09<00:00, 102.97it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.6278832 , -0.33456907,  0.1226691 , ...,  0.0171999 ,\n",
              "        1.1594708 , -0.9362    ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "from HGR_NN.Fair_hgr_nn import FAIR_HGR_NN\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "H = 15\n",
        "H2 = 15\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Predictor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Predictor, self).__init__()\n",
        "        self.fc1 = nn.Linear(X_train.shape[1], 64)\n",
        "        self.fc2 = nn.Linear(64, 8)\n",
        "        self.fc3 = nn.Linear(8, 4)\n",
        "        self.fc4 = nn.Linear(4, 1)\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        #x = F.dropout(x, p=0.8)\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "        #x = F.dropout(x, p=0.8)\n",
        "        x = self.fc3(x)\n",
        "        x = F.relu(x)\n",
        "        #x = F.dropout(x, p=0.8)\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Net_HGR(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net_HGR, self).__init__()\n",
        "        self.fc1 = nn.Linear(1, H)\n",
        "        self.fc2 = nn.Linear(H, H)\n",
        "        self.fc3 = nn.Linear(H, H2)\n",
        "        self.fc4 = nn.Linear(H2, 1)\n",
        "        self.bn1 = nn.BatchNorm1d(1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h1 = torch.tanh(self.fc1(x))\n",
        "        h2 = torch.relu(self.fc2(h1))\n",
        "        h3 = torch.tanh(self.fc3(h2))\n",
        "        h4 = torch.tanh(self.fc4(h3))\n",
        "        return h4\n",
        "class Net2_HGR(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net2_HGR, self).__init__()\n",
        "        self.fc1 = nn.Linear(1, H)\n",
        "        self.fc2 = nn.Linear(H, H)\n",
        "        self.fc3 = nn.Linear(H, H2)\n",
        "        self.fc4 = nn.Linear(H2, 1)\n",
        "        self.bn1 = nn.BatchNorm1d(1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h1 = torch.tanh(self.fc1(x))\n",
        "        h2 = torch.relu(self.fc2(h1))\n",
        "        h3 = torch.tanh(self.fc3(h2))\n",
        "        h4 = torch.tanh(self.fc4(h3))\n",
        "        return h4\n",
        "import torch\n",
        "\n",
        "device = torch.device(str(\"cuda:0\") if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "lamb_HGR=0 #  so unfair model since no loop over HGR (start_epochHGR >= nbepoch) and LAMBDA = 0\n",
        "UNFair_NN_S0 = FAIR_HGR_NN(regressor=\"rmse\",mod_h=Predictor, p_device =device,\n",
        "                            nbepoch =1000 , lr = 0.0005, lambdaHGR=lamb_HGR, nbepochHGR=5, start_epochHGR=1000\n",
        "                              ,mod_HGR_F=Net_HGR,mod_HGR_G= Net2_HGR, init_HGR=False)\n",
        "\n",
        "UNFair_NN_S0.fit(X_train, y_train, s_train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "84418bcd",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T18:20:41.032176Z",
          "start_time": "2024-01-04T18:20:35.424313Z"
        },
        "code_folding": [],
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84418bcd",
        "outputId": "6121d4ff-6b8b-48d9-fe72-9ebc4fb31dab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE Test 0.2922\n",
            "HGR NN Test 0.2386583\n",
            "HGR RDC Test 0.21326508678638006\n",
            "HGR KDE Test 0.17493503\n",
            "FairQuant Test 0.07343925915658474\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "H = 15\n",
        "H2 = 15\n",
        "\n",
        "\n",
        "class Net_HGR(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net_HGR, self).__init__()\n",
        "        self.fc1 = nn.Linear(1, H)\n",
        "        self.fc2 = nn.Linear(H, H)\n",
        "        self.fc3 = nn.Linear(H, H2)\n",
        "        self.fc4 = nn.Linear(H2, 1)\n",
        "        self.bn1 = nn.BatchNorm1d(1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h1 = torch.tanh(self.fc1(x))\n",
        "        h2 = torch.relu(self.fc2(h1))\n",
        "        h3 = torch.tanh(self.fc3(h2))\n",
        "        h4 = torch.tanh(self.fc4(h3))\n",
        "        return h4\n",
        "\n",
        "\n",
        "class Net2_HGR(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net2_HGR, self).__init__()\n",
        "        self.fc1 = nn.Linear(1, H)\n",
        "        self.fc2 = nn.Linear(H, H)\n",
        "        self.fc3 = nn.Linear(H, H2)\n",
        "        self.fc4 = nn.Linear(H2, 1)\n",
        "        self.bn1 = nn.BatchNorm1d(1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h1 = torch.tanh(self.fc1(x))\n",
        "        h2 = torch.relu(self.fc2(h1))\n",
        "        h3 = torch.tanh(self.fc3(h2))\n",
        "        h4 = torch.tanh(self.fc4(h3))\n",
        "        return h4\n",
        "\n",
        "from HGR_NN.functions import *\n",
        "\n",
        "y_pred = UNFair_NN_S0.predict(X_train)\n",
        "y_predt = UNFair_NN_S0.predict(X_test)\n",
        "y_pred_np=y_pred.cpu().detach().numpy().squeeze(1)\n",
        "y_predt_np=y_predt.cpu().detach().numpy().squeeze(1)\n",
        "MSE = round(np.mean((y_train-y_pred_np)**2),4)\n",
        "MSEt = round(np.mean((y_test-y_predt_np)**2),4)\n",
        "\n",
        "HGR_NNP = HGR_NN(Net_HGR(),Net2_HGR(),device, display=False)\n",
        "print(\"MSE Test\", MSEt)\n",
        "print(\"HGR NN Test\",HGR_NNP(y_predt_np, s_test,1000 ))\n",
        "print(\"HGR RDC Test\", rdc(y_predt_np, s_test))\n",
        "print(\"HGR KDE Test\",hgr(y_predt.squeeze(1).to(\"cpu\"), torch.FloatTensor(s_test).to(\"cpu\"),kde).data.numpy())\n",
        "print(\"FairQuant Test\", FairQuant(s_test,y_test,y_predt_np))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c96b4313",
      "metadata": {
        "id": "c96b4313"
      },
      "source": [
        "\n",
        "### 3) A QUICK FAIR MODEL VIA HGR NN MINIMIZATION (no need of GPU)\n",
        "(Quick since there are only 50 epochs of the HGR minimization and no HGR Initialization  (1000 when starting))\n",
        "--> please note that with only 50 epochs the performance are a little bit less robust and less performant. In section 4) you will train a more robust model with 500 epochs on the HGR (better with GPU! )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "26acef99",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-04T20:25:38.561124Z",
          "start_time": "2024-01-04T20:23:56.003274Z"
        },
        "code_folding": [],
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26acef99",
        "outputId": "05372cda-6a27-463c-b193-5bf511afbc7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Bar desc (file 1000): 100%|██████████| 1001/1001 [00:19<00:00, 51.15it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.50174505,  0.17450356,  0.03181195, ...,  0.19036525,\n",
              "        0.73147553, -0.9183152 ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "\n",
        "from HGR_NN.Fair_hgr_nn import FAIR_HGR_NN\n",
        "\n",
        "\n",
        "class Predictor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Predictor, self).__init__()\n",
        "        self.fc1 = nn.Linear(X_train.shape[1], 64)\n",
        "        self.fc2 = nn.Linear(64, 8)\n",
        "        self.fc3 = nn.Linear(8, 4)\n",
        "        self.fc4 = nn.Linear(4, 1)\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        #x = F.dropout(x, p=0.8)\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "        #x = F.dropout(x, p=0.8)\n",
        "        x = self.fc3(x)\n",
        "        x = F.relu(x)\n",
        "        #x = F.dropout(x, p=0.8)\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "H = 15\n",
        "H2 = 15\n",
        "\n",
        "\n",
        "class Net_HGR(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net_HGR, self).__init__()\n",
        "        self.fc1 = nn.Linear(1, H)\n",
        "        self.fc2 = nn.Linear(H, H)\n",
        "        self.fc3 = nn.Linear(H, H2)\n",
        "        self.fc4 = nn.Linear(H2, 1)\n",
        "        self.bn1 = nn.BatchNorm1d(1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h1 = torch.tanh(self.fc1(x))\n",
        "        h2 = torch.relu(self.fc2(h1))\n",
        "        h3 = torch.tanh(self.fc3(h2))\n",
        "        h4 = torch.tanh(self.fc4(h3))\n",
        "        return h4\n",
        "class Net2_HGR(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net2_HGR, self).__init__()\n",
        "        self.fc1 = nn.Linear(1, H)\n",
        "        self.fc2 = nn.Linear(H, H)\n",
        "        self.fc3 = nn.Linear(H, H2)\n",
        "        self.fc4 = nn.Linear(H2, 1)\n",
        "        self.bn1 = nn.BatchNorm1d(1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h1 = torch.tanh(self.fc1(x))\n",
        "        h2 = torch.relu(self.fc2(h1))\n",
        "        h3 = torch.tanh(self.fc3(h2))\n",
        "        h4 = torch.tanh(self.fc4(h3))\n",
        "        return h4\n",
        "\n",
        "device = torch.device(str(\"cuda:0\") if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "lamb_HGR=2.5\n",
        "Fair_HGR_NN_S0 = FAIR_HGR_NN(regressor=\"rmse\",mod_h=Predictor,  p_device =device,\n",
        "                            nbepoch =1000 , lr = 0.0005, lambdaHGR=lamb_HGR, nbepochHGR=50, start_epochHGR=950\n",
        "                              ,mod_HGR_F=Net_HGR,mod_HGR_G= Net2_HGR, init_HGR= False)\n",
        "\n",
        "\n",
        "Fair_HGR_NN_S0.fit(X_train, y_train, s_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "H = 15\n",
        "H2 = 15\n",
        "\n",
        "\n",
        "class Net_HGR(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net_HGR, self).__init__()\n",
        "        self.fc1 = nn.Linear(1, H)\n",
        "        self.fc2 = nn.Linear(H, H)\n",
        "        self.fc3 = nn.Linear(H, H2)\n",
        "        self.fc4 = nn.Linear(H2, 1)\n",
        "        self.bn1 = nn.BatchNorm1d(1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h1 = torch.tanh(self.fc1(x))\n",
        "        h2 = torch.relu(self.fc2(h1))\n",
        "        h3 = torch.tanh(self.fc3(h2))\n",
        "        h4 = torch.tanh(self.fc4(h3))\n",
        "        return h4\n",
        "\n",
        "\n",
        "class Net2_HGR(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net2_HGR, self).__init__()\n",
        "        self.fc1 = nn.Linear(1, H)\n",
        "        self.fc2 = nn.Linear(H, H)\n",
        "        self.fc3 = nn.Linear(H, H2)\n",
        "        self.fc4 = nn.Linear(H2, 1)\n",
        "        self.bn1 = nn.BatchNorm1d(1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h1 = torch.tanh(self.fc1(x))\n",
        "        h2 = torch.relu(self.fc2(h1))\n",
        "        h3 = torch.tanh(self.fc3(h2))\n",
        "        h4 = torch.tanh(self.fc4(h3))\n",
        "        return h4\n",
        "\n",
        "from HGR_NN.functions import *\n",
        "from HGR_NN.functions import HGR_NN\n",
        "\n",
        "y_pred = Fair_HGR_NN_S0.predict(X_train)\n",
        "y_predt = Fair_HGR_NN_S0.predict(X_test)\n",
        "\n",
        "y_pred_np=y_pred.cpu().detach().numpy().squeeze(1)\n",
        "y_predt_np=y_predt.cpu().detach().numpy().squeeze(1)\n",
        "MSE = round(np.mean((y_train-y_pred_np)**2),4)\n",
        "MSEt = round(np.mean((y_test-y_predt_np)**2),4)\n",
        "\n",
        "HGR_NNP = HGR_NN(Net_HGR(),Net2_HGR(),device, display=False)\n",
        "print(\"MSE Test\", MSEt)\n",
        "print(\"HGR NN Test\",HGR_NNP(y_predt_np, s_test,100))\n",
        "print(\"HGR RDC Test\", rdc(y_predt_np, s_test))\n",
        "print(\"HGR KDE Test\",hgr(y_predt.squeeze(1).to(\"cpu\"), torch.FloatTensor(s_test).to(\"cpu\"),kde).data.numpy())\n",
        "print(\"FairQuant Test\", FairQuant(s_test,y_test,y_predt_np))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYGMfUoDN5nN",
        "outputId": "20a82f54-e698-4a81-9688-1b818f730495"
      },
      "id": "vYGMfUoDN5nN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE Test 0.5294\n",
            "HGR NN Test 0.06170071\n",
            "HGR RDC Test 0.050341320491113\n",
            "HGR KDE Test 0.05167916\n",
            "FairQuant Test 0.0236079566180706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 4) A MORE ROBUST FAIR MODEL (Better with GPU)\n",
        "\"Init_HGR=True\" allows to make a better HGR Initialization  (1000 epochs when it starts mitigating with HGR)\n",
        "--> please note that there will be now 500 epochs of HGR minimization (instead of 50 as before). Also note that for each epoch 50 epochs of HGR are applied! so it can be long and a GPU can help (with device = 'cuda:0')\n"
      ],
      "metadata": {
        "id": "zL0uSDzHZiod"
      },
      "id": "zL0uSDzHZiod"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from HGR_NN.Fair_hgr_nn import FAIR_HGR_NN\n",
        "\n",
        "\n",
        "class Predictor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Predictor, self).__init__()\n",
        "        self.fc1 = nn.Linear(X_train.shape[1], 64)\n",
        "        self.fc2 = nn.Linear(64, 8)\n",
        "        self.fc3 = nn.Linear(8, 4)\n",
        "        self.fc4 = nn.Linear(4, 1)\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        #x = F.dropout(x, p=0.8)\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "        #x = F.dropout(x, p=0.8)\n",
        "        x = self.fc3(x)\n",
        "        x = F.relu(x)\n",
        "        #x = F.dropout(x, p=0.8)\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "H = 15\n",
        "H2 = 15\n",
        "\n",
        "\n",
        "class Net_HGR(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net_HGR, self).__init__()\n",
        "        self.fc1 = nn.Linear(1, H)\n",
        "        self.fc2 = nn.Linear(H, H)\n",
        "        self.fc3 = nn.Linear(H, H2)\n",
        "        self.fc4 = nn.Linear(H2, 1)\n",
        "        self.bn1 = nn.BatchNorm1d(1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h1 = torch.tanh(self.fc1(x))\n",
        "        h2 = torch.relu(self.fc2(h1))\n",
        "        h3 = torch.tanh(self.fc3(h2))\n",
        "        h4 = torch.tanh(self.fc4(h3))\n",
        "        return h4\n",
        "class Net2_HGR(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net2_HGR, self).__init__()\n",
        "        self.fc1 = nn.Linear(1, H)\n",
        "        self.fc2 = nn.Linear(H, H)\n",
        "        self.fc3 = nn.Linear(H, H2)\n",
        "        self.fc4 = nn.Linear(H2, 1)\n",
        "        self.bn1 = nn.BatchNorm1d(1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h1 = torch.tanh(self.fc1(x))\n",
        "        h2 = torch.relu(self.fc2(h1))\n",
        "        h3 = torch.tanh(self.fc3(h2))\n",
        "        h4 = torch.tanh(self.fc4(h3))\n",
        "        return h4\n",
        "\n",
        "device = torch.device(str(\"cuda:0\") if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "lamb_HGR=3\n",
        "Fair_HGR_NN_S1 = FAIR_HGR_NN(regressor=\"rmse\",mod_h=Predictor,  p_device =device,\n",
        "                            nbepoch =1500 , lr = 0.0005, lambdaHGR=lamb_HGR, nbepochHGR=50, start_epochHGR=1000\n",
        "                              ,mod_HGR_F=Net_HGR,mod_HGR_G= Net2_HGR,init_HGR=True)\n",
        "\n",
        "\n",
        "Fair_HGR_NN_S1.fit(X_train, y_train, s_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61PlHX0WZpGP",
        "outputId": "a4d20e78-b6b8-4fcd-d0f9-50d4a0c0802c"
      },
      "id": "61PlHX0WZpGP",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Bar desc (file 1500): 100%|██████████| 1501/1501 [02:02<00:00, 12.23it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.7393369 , -0.02141701, -0.13145773, ...,  0.23513974,\n",
              "        0.21242495, -0.9526018 ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "H = 15\n",
        "H2 = 15\n",
        "\n",
        "\n",
        "class Net_HGR(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net_HGR, self).__init__()\n",
        "        self.fc1 = nn.Linear(1, H)\n",
        "        self.fc2 = nn.Linear(H, H)\n",
        "        self.fc3 = nn.Linear(H, H2)\n",
        "        self.fc4 = nn.Linear(H2, 1)\n",
        "        self.bn1 = nn.BatchNorm1d(1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h1 = torch.tanh(self.fc1(x))\n",
        "        h2 = torch.relu(self.fc2(h1))\n",
        "        h3 = torch.tanh(self.fc3(h2))\n",
        "        h4 = torch.tanh(self.fc4(h3))\n",
        "        return h4\n",
        "\n",
        "\n",
        "class Net2_HGR(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net2_HGR, self).__init__()\n",
        "        self.fc1 = nn.Linear(1, H)\n",
        "        self.fc2 = nn.Linear(H, H)\n",
        "        self.fc3 = nn.Linear(H, H2)\n",
        "        self.fc4 = nn.Linear(H2, 1)\n",
        "        self.bn1 = nn.BatchNorm1d(1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h1 = torch.tanh(self.fc1(x))\n",
        "        h2 = torch.relu(self.fc2(h1))\n",
        "        h3 = torch.tanh(self.fc3(h2))\n",
        "        h4 = torch.tanh(self.fc4(h3))\n",
        "        return h4\n",
        "\n",
        "from HGR_NN.functions import *\n",
        "from HGR_NN.functions import HGR_NN\n",
        "\n",
        "y_pred = Fair_HGR_NN_S1.predict(X_train)\n",
        "y_predt = Fair_HGR_NN_S1.predict(X_test)\n",
        "\n",
        "y_pred_np=y_pred.cpu().detach().numpy().squeeze(1)\n",
        "y_predt_np=y_predt.cpu().detach().numpy().squeeze(1)\n",
        "MSE = round(np.mean((y_train-y_pred_np)**2),4)\n",
        "MSEt = round(np.mean((y_test-y_predt_np)**2),4)\n",
        "\n",
        "HGR_NNP = HGR_NN(Net_HGR(),Net2_HGR(),device, display=False)\n",
        "print(\"MSE Test\", MSEt)\n",
        "print(\"HGR NN Test\",HGR_NNP(y_predt_np, s_test,100))\n",
        "print(\"HGR RDC Test\", rdc(y_predt_np, s_test))\n",
        "print(\"HGR KDE Test\",hgr(y_predt.squeeze(1).to(\"cpu\"), torch.FloatTensor(s_test).to(\"cpu\"),kde).data.numpy())\n",
        "print(\"FairQuant Test\", FairQuant(s_test,y_test,y_predt_np))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bzl_xGCwZ305",
        "outputId": "27ddfc2a-cb9c-4daa-a3ec-6e169a7295e0"
      },
      "id": "Bzl_xGCwZ305",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE Test 0.5213\n",
            "HGR NN Test 0.05264287\n",
            "HGR RDC Test 0.04489993367342854\n",
            "HGR KDE Test 0.047230523\n",
            "FairQuant Test 0.01774695102125406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ajEjEN5XdAFh"
      },
      "id": "ajEjEN5XdAFh",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:Transf] *",
      "language": "python",
      "name": "conda-env-Transf-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}